{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Readme\n",
    "\n",
    "* The pre-trained model file is available here - https://drive.google.com/file/d/1zQ0WQ8IugTYGKh5rriCxj_FLusXFuZI4/view?usp=sharing\n",
    "* for both the below mentioned evaluation/testing methods, you need to download the file, keep the **file as it is with the same name** in the `./model/` directory.\n",
    "\n",
    "* Both the inference methods are tested on linux machines on CPU with 8GB RAM\n",
    "\n",
    "**Replicating the inference results on custom data**\n",
    "1. The easy way to replicate the prediction setup is using docker. See [Custom prediction - method 1](#custom1)\n",
    "2. If you want to check the prediction without using docker, you may need to follow the instructions given in the [Custom prediction - method 2](#custom2)\n",
    "\n",
    "\n",
    "*Any queries or bugs? Reach out to renjithbaby23@gmail.com*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='custom1'></a>\n",
    "## Custom prediction - method 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction using the docker**\n",
    "\n",
    "*If you are not familiad with docker, just follow the instructions. But first install docker from - https://docs.docker.com/engine/install/*\n",
    "\n",
    "1. You should have docker installed for this to work\n",
    "2. Clone the repo - `git clone https://github.com/renjithbaby23/sentiment-classification.git`\n",
    "3. cd to the repo - `cd sentiment-classification`\n",
    "4. Enusre that you have downloaded the [model file](https://drive.google.com/file/d/1zQ0WQ8IugTYGKh5rriCxj_FLusXFuZI4/view?usp=sharing) and is available at `./model/model.tar.gz`\n",
    "4. Build the docker image - `docker build ./ -t renjith/sentiment:v1`\n",
    "5. Run the docker container - `docker run -d --name sentiment-serving -p 80:80 renjith/sentiment:v1`\n",
    "6. From the same machine where you ran the docker, go to the url -`http://0.0.0.0:80/sentiment-detection/health` to check if the service is up and running.\n",
    "\n",
    "*If ip 0.0.0.0 is not working on local machine, you can use `http://localhost:80/sentiment-detection/health` instead*\n",
    "\n",
    "*If you are getting some error related to port already in use, try googling for how to stop the processes running on the same port and you may need to kill them*\n",
    "\n",
    "\n",
    "Run the below cells to test the model via locally available apis with custom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install requests==2.24.0\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modify the string below if you want to test on your own data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = 'how can I login to app store?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted sentiment is: 'neutral' with confidence: 0.89651954\n"
     ]
    }
   ],
   "source": [
    "# the endpoint that will be created when the docker is running\n",
    "local_api = \"http://0.0.0.0:80/sentiment-detection/predict\"\n",
    "# in case if the above is not working, you can use the below local api\n",
    "# local_api = \"http://localhost:80/sentiment-detection/predict\"\n",
    "\n",
    "# preparing the payload\n",
    "data = {'content': sample_text}\n",
    "\n",
    "# get the response\n",
    "response = requests.request('POST', local_api, json=data)\n",
    "\n",
    "# parsing the response\n",
    "prediction = response.json()\n",
    "\n",
    "print(\"The predicted sentiment is: '{}' with confidence: {}\"\\\n",
    "      .format(prediction['data']['decision'], \\\n",
    "              prediction['data']['prediction confidence']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleaning up the docker image and running containers**\n",
    "\n",
    "1. stop the running container -  `docker stop sentiment-serving`\n",
    "2. remove the container - `docker rm sentiment-serving`\n",
    "3. remove the docker image - `docker image rm renjith/sentiment:v1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='custom2'></a>\n",
    "## Custom prediction - method 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you want to do the testing manually on custom data, follow the steps**\n",
    "\n",
    "1. Create a conda environment with python 3.8 `sentiment`\n",
    "2. Activate the environment `sentiment`\n",
    "3. Install the requirements `pip install -r requirements.txt`\n",
    "5. Untar the [model file](https://drive.google.com/file/d/1zQ0WQ8IugTYGKh5rriCxj_FLusXFuZI4/view?usp=sharing) using `tar xzf model.tar.gz`\n",
    "6. keep the extracted folder **without renaming** - here `./model/apple5_model/`\n",
    "7. If the TF saved model is kept in a different folder, update the below variable `saved_model_path`\n",
    "8. Modify the list `test_data` with your custom text to see the predictions\n",
    "9. Run the below cells of this notebook\n",
    "10. You can also run the evaluation.py once you are done with the steps till 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_path = './model/apple5_model/'\n",
    "class_names = {0: \"neutral\", 1: \"positive\", 2:\"negative\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded_model = tf.saved_model.load(saved_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can modify the `test_data` to test the model with your custom text contents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [\n",
    "    'this is such an amazing movie!',\n",
    "    'The movie was great!',\n",
    "    'The movie was meh.',\n",
    "    'The movie was okish.',\n",
    "    'The movie was terrible...',\n",
    "    'how can I login to app store?'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      "input: this is such an amazing movie! : score: [0.00374165 0.99136215 0.00489621]  : class: positive\n",
      "input: The movie was great!           : score: [0.00444103 0.9867165  0.00884238]  : class: positive\n",
      "input: The movie was meh.             : score: [0.22289388 0.6971025  0.08000361]  : class: positive\n",
      "input: The movie was okish.           : score: [0.07919218 0.868262   0.05254583]  : class: positive\n",
      "input: The movie was terrible...      : score: [0.00729853 0.01884586 0.9738556 ]  : class: negative\n",
      "input: how can I login to app store?  : score: [0.89651954 0.02201089 0.08146948]  : class: neutral\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_my_examples(inputs, results):\n",
    "  result_for_printing = \\\n",
    "    [f'input: {inputs[i]:<30} : score: {results[i]}  : class: {class_names[np.argmax(results[i])]}'\n",
    "                         for i in range(len(inputs))]\n",
    "  print(*result_for_printing, sep='\\n')\n",
    "  print()\n",
    "\n",
    "reloaded_results = reloaded_model(tf.constant(test_data))\n",
    "\n",
    "print('Predictions:')\n",
    "print_my_examples(test_data, reloaded_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
